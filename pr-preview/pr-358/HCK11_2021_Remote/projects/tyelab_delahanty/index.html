<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NWB Workshops and Hackathons | Materials related to the Neurodata Without Borders (NWB) User Days Workshops and Hackathons</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="NWB Workshops and Hackathons" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Materials related to the Neurodata Without Borders (NWB) User Days Workshops and Hackathons" />
<meta property="og:description" content="Materials related to the Neurodata Without Borders (NWB) User Days Workshops and Hackathons" />
<link rel="canonical" href="http://nwb.org/nwb_hackathons/HCK11_2021_Remote/projects/tyelab_delahanty/" />
<meta property="og:url" content="http://nwb.org/nwb_hackathons/HCK11_2021_Remote/projects/tyelab_delahanty/" />
<meta property="og:site_name" content="NWB Workshops and Hackathons" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="NWB Workshops and Hackathons" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Materials related to the Neurodata Without Borders (NWB) User Days Workshops and Hackathons","headline":"NWB Workshops and Hackathons","url":"http://nwb.org/nwb_hackathons/HCK11_2021_Remote/projects/tyelab_delahanty/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/nwb_hackathons/assets/css/style.css?v=c195892c536e8b7cdc1c45d8570b96d2f6ed4aec">
    <link rel="shortcut icon" type="image/png" href="/nwb_hackathons/assets/favicon_96.png?v=c195892c536e8b7cdc1c45d8570b96d2f6ed4aec">


    <!-- for github edit ribbon; main include is in `assets/css/style.scss` -->
<!--[if lt IE 9]>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.0/gh-fork-ribbon.ie.min.css" />
<![endif]-->

  </head>
  <body>

    <a class="github-fork-ribbon" href="https://github.com/NeurodataWithoutBorders/nwb_hackathons/edit/main/HCK11_2021_Remote/projects/tyelab_delahanty/README.md" data-ribbon="Edit this page" title="Edit this page">Edit this page</a>

    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="http://nwb.org/nwb_hackathons/">NWB Workshops and Hackathons</a></h1>
      

      <p><a href="/nwb_hackathons/HCK11_2021_Remote/#ProjectsList"><img class="emoji" title=":rewind:" alt=":rewind:" src="https://github.githubassets.com/images/icons/emoji/unicode/23ea.png" height="20" width="20"> Back to the projects list</a></p>

<!-- For information on how to write GitHub .md files see https://guides.github.com/features/mastering-markdown/ -->

<h1 id="tye-lab-2p-data-nwb-conversion-jeremy">Tye Lab 2P Data NWB Conversion (Jeremy)</h1>

<h2 id="key-investigators">Key Investigators</h2>

<p>Jeremy Delahanty (The Salk Institute for Biological Studies)</p>

<h2 id="project-description">Project Description</h2>

<p>This project is intended to convert currently existing 2P datasets - which
contain optical physiology, mouse headfixed behavior, mouse face recordings,
and configuration files - into datasets compliant with NWB.</p>

<h2 id="objectives">Objectives</h2>

<p>I aim to convert at least the mouse behavior recordings and 2P datasets into
NWB compliant datasets.</p>

<ol>
  <li>
    <p>Behavior Datasets: Convert the raw csv output from Bruker Microscopy DAQ
into a raw NWB file, clean it and format stimuli events into a dynamic table,
and finally incorporating licks into the dataset as events.</p>
  </li>
  <li>
    <p>2P Datasets: Convert raw Bruker Microscopy files into NWB complaint hdf5
format.</p>
  </li>
</ol>

<h2 id="approach-and-plan">Approach and Plan</h2>

<p>Behavior Data</p>
<ul>
  <li>Data has been cleaned into pandas dataframes from the raw csv files and
  then written to HDF5. However, after speaking with Ryan Ly, it should be
  done in a different way so people writing in MATLAB <em>or</em> Python can use it.
    <ol>
      <li>Write raw csv into NWB HDF5</li>
      <li>Clean data into timestamps and populate a dynamic table for stimuli and
  an events list for licking behavior</li>
      <li>Write out configuration file of experimental metadata to the NWB file</li>
    </ol>
  </li>
</ul>

<p>2P Data</p>
<ul>
  <li>Data is written at runtime to disk in Bruker’s proprietary format and then
  converted into tiffs using their imaging ripping utility. These tiffs are
  merged into one HDF5 file in MATLAB but not in NWB format.
    <ol>
      <li>Use Deisseroth Lab’s repository to containerize the image ripping utility
  and deploy on SNL hardware.</li>
      <li>Take results of their ripper and put them into NWB file seamlessly</li>
      <li>Use Suite2p/CaImAn to perform motion correction, DeltaF/F
  calculation, and cell registration for the dataset.</li>
    </ol>
  </li>
</ul>

<h2 id="progress-and-next-steps">Progress and Next Steps</h2>

<p>8/25/21: Didn’t work on this much this day.</p>

<p>8/26/21: Starting building base NWB file as part of experiment runtime.
I can build NWB files no problem, but need to determine which fields
I can automate/gather from XML file for imaging/configuration files.
I’m also trying to find out how to make the NWB Subject format fit
into the data framework, need some assistance there. Containerization
for 2P writing will be worked on tomorrow/this weekend using both
CaImAn and Suite2p so I can compare the process for each version.
I also need to ask about how to put the raw CSV file, XML file, and
raw Bruker format into NWB as well/determine if it’s needed at all.</p>

<p>8/28/21 &amp; 8/29/21: Gathered metadata from Bruker’s Prairie View and 
built project specific yml files for configuration values. One day
this should definitely be made into a database, probably with DJ.
These metadata then populate an NWB file which currently has the
following information built: Lab/experimenter, devices, imaging plane.
There’s a few things I need to double check about what’s the appropriate
values for the fields in the file, but I made a fair bit of progress
this evening with automating the building of relevant metadata for NWB
the moment the microscopy session (read: imaging plane) ends.</p>

<p>8/30/21: I’ve completed building a base NWB file but need to review
it with someone from the Dev team before I feel confident pushing it
into production. Struggled to understand the Subject file and how to
use it properly, but will be hopefully getting advice soon. Main
problem was how I’ll need multiple weights accounted for per animal
but that functionality doesn’t appear to be present in NWB. There’s
additional metadata that I think makes sense to incorporate into the
system such as laser power and PMT gains, but I see no way to do so
in NWB. I still need to build a base behavior part of the dataset as
well and review what makes sense to have timestamp wise for given
behavior datasets.</p>

<p>9/13/21: A week ago, with the help of Ryan Ly, I finally got
all the available base metadata written to an NWB file the moment the
experiment is over! I’ve been informed of the different kinds of
things that require extensions so I will be working on those in the
coming weeks. Forgot to update here…</p>

<p>9/26/21: Started writing an extension for including Arduino config
metadata that’s used for performing the behavior experiments this
evening. A little stuck on the next steps file, but slowly working
through it. The planned extensions I’ll be writing are to include
the following:</p>
<ul>
  <li>Arduino metadata used for configuring behavior experiment</li>
  <li>More specific surgery information for the surgery field in <code class="language-plaintext highlighter-rouge">Subject</code>
</li>
  <li>Additional metadata about pockel and PMT values used during imaging</li>
  <li>Behavior specific metadata (i.e. sucrose concentration, air PSI)</li>
  <li>Mouse facial expression recordings with associated metadata</li>
</ul>

<p>A complete NWB File for the Bruker 2P setup will thus include:
<em>Raw Data</em></p>
<ul>
  <li>Raw behavior data (voltage recording)</li>
  <li>Raw video of mouse face</li>
  <li>Raw 2P Data</li>
  <li>Raw Z-stacks (likely 8 - 16 of them) per indicator</li>
  <li>Arduino configuration</li>
  <li>Trial structure configuration</li>
  <li>Behavioral setup metadata</li>
  <li>Laser/PMT/Pockel/Scope objective configuration for T-Series</li>
  <li>Laser/PMT/Pockel/Scope objective configuration for Z-Stacks</li>
</ul>

<p><em>Processed Data</em></p>
<ul>
  <li>Reference image for recordings from Suite2P</li>
  <li>Suite2p configurations for segmentation/analysis</li>
  <li>Motion corrected t-series</li>
  <li>Cell registrations as <code class="language-plaintext highlighter-rouge">optical-channels</code>
</li>
  <li>Cell traces</li>
  <li>Spike deconvolution (maybe…)</li>
  <li>Averaged z-stacks</li>
  <li>HOG Matrcies of mouse facial expression</li>
  <li>Mouse behavior timestamps from trial structures according to paper’s analysis</li>
  <li>More?</li>
</ul>

<h2 id="materials">Materials</h2>

<p>The developments can be followed along in the bruker_control folder
in the git repo below’s source code in the branch:
“bruker_control_refactor”</p>

<p>8/29/21: If you want to see the updates from the above progress notes,
check out the nwb_utils.py file in the bruker_control folder. It’s
quite messy in there for now, but hopefully it does make a little
sense if you look around.</p>

<p>9/13/21: The bruker_control refactor that includes the completed
nwb_utils module is complete! You can check it out on the repo if
you want. There’s also better documentation for things now on the
linked readthedocs site below.</p>

<h2 id="background-and-references">Background and References</h2>

<p>Bruker Microscopy built Prairie View for recording 2P data and provided an API
that can be interacted with in Python, MATLAB, and C/C++. The system I’ve
written to govern the experiment uses Python and is called ‘bruker_control’.
It’s part of a repository that was developed with my lab mates to unite
imaging, stimuli, behavior, and video of the mouse’s face into one program.</p>

<p>The source code for the repository is linked below as is a first iteration of
some documentation hosted on readthedocs that is still very much under
development.</p>

<p>Source code: https://github.com/Tyelab/headfix_control</p>

<p>Documentation: https://bruker-control.readthedocs.io/en/latest/</p>


    </div>

    <script src="/nwb_hackathons/assets/javascript/anchor-js/anchor.min.js"></script>
    <script>anchors.add();</script>
    
    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-134749152-2', 'auto');
      ga('send', 'pageview');
    </script>
    
  </body>
</html>
