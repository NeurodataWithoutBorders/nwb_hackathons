{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and exploring NWB data from DANDI\n",
    "\n",
    "This tutorial will demonstrate how to download, explore, and do basic visualizations with\n",
    "an NWB File from DANDI.\n",
    "\n",
    "**Our goals are to learn how to:**\n",
    "- Download data from the [DANDI archive](https://gui.dandiarchive.org/)\n",
    "- Read and explore an NWB file\n",
    "- Do basic visualizations of NWB data\n",
    "- Stream data from the [DANDI archive](https://gui.dandiarchive.org/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Before we get started, let's import a few libraries that we will use for accessing and visualizing the data. \n",
    "\n",
    "If you *are not* running this notebook on DANDI Hub, you will first need to install these packages using `pip` or your favorite Python package manager. For example:\n",
    "```\n",
    "pip install dandi pynwb remfile matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you *are* running this notebook on DANDI Hub, all packages should be pre-installed except for `remfile`. We can install this package using the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install remfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pathlib\n",
    "import remfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dandi.download import download\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data from the DANDI archive\n",
    "\n",
    "In this notebook we will be working with NWB data from one session of an experiment by\n",
    "[Chandravadia et al. (2020)](https://www.nature.com/articles/s41597-020-0415-9). In this study,\n",
    "the authors recorded single neuron activity from the medial temporal lobes of human subjects\n",
    "while they performed a recognition memory task. This data can be found on the [DANDI Archive](https://gui.dandiarchive.org/) in [Dandiset 000004](https://gui.dandiarchive.org/dandiset/000004).\n",
    "\n",
    "\n",
    "There are multiple ways to download data from DANDI:\n",
    "1.  Downloading data using the DANDI Web UI\n",
    "2.  Downloading data programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading data using the DANDI Web UI\n",
    "You can download files directly from the DANDI website.\n",
    "\n",
    "1. Go to dataset [000004](https://gui.dandiarchive.org/dandiset/000004) on the DANDI archive.\n",
    "2. List the files in this dataset by clicking the \"Files\" button in Dandiset Actions (top right column of the page).\n",
    "\n",
    "<img src=\"https://pynwb.readthedocs.io/en/latest/_images/demo_dandi_view_files_in_dataset.png\" width=\"700\" alt=\"view files on dandi\" align=\"center\">\n",
    "\n",
    "3. Choose the folder \"sub-P11MHM\" by clicking on its name.\n",
    "\n",
    "<img src=\"https://pynwb.readthedocs.io/en/latest/_images/demo_dandi_select_folder.png\" width=\"700\" alt=\"selecting a folder on dandi\" align=\"center\">\n",
    "\n",
    "4. Download the NWB data file \"sub-P11HMH_ses-20061101_ecephys+image.nwb\" to your\n",
    "computer by clicking on the download symbol.\n",
    "\n",
    "<img src=\"https://pynwb.readthedocs.io/en/latest/_images/demo_dandi_download_data.png\" width=\"700\" alt=\"selecting a folder on dandi\" align=\"center\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Downloading data programmatically\n",
    "Alternatively, you can download data using the `DandiAPIClient` from the `dandi` Python package. Using the dandiset id and file path, we can use the dandi api to download the NWB file.\n",
    "\n",
    "You can learn more about the dandi API in the [DANDI Python API docs](https://dandi.readthedocs.io/en/stable/modref/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = '000004'\n",
    "filepath = 'sub-P11HMH/sub-P11HMH_ses-20061101_ecephys+image.nwb'\n",
    "with DandiAPIClient() as client:\n",
    "    dandiset = client.get_dandiset(dandiset_id)\n",
    "    asset = dandiset.get_asset_by_path(filepath)\n",
    "    download(asset.download_url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset.download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Exploring an NWB file\n",
    "\n",
    "An [NWBFile](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile) represents a single session of an experiment.\n",
    "It contains all the data of that session and the metadata required to understand the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the NWB file\n",
    "Reading and writing NWB data is carried out using the `NWBHDF5IO` class.\n",
    "`NWBHDF5IO` reads and writes NWB data that is in the [HDF5](https://www.hdfgroup.org/solutions/hdf5/)\n",
    "storage format, a popular, hierarchical format for storing large-scale scientific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the NWBHDF5IO read method\n",
    "The first argument to the constructor of `NWBHDF5IO` is the ``file_path``. Use the ``read`` method to read the data into a `NWBFile` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Open the file in read mode \"r\",\n",
    "filepath = \"sub-P11HMH_ses-20061101_ecephys+image.nwb\"\n",
    "io = NWBHDF5IO(filepath, mode=\"r\")\n",
    "nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the `NWBFile` object in a Jupyter notebook to get a simplified, interactive representation of the contents of the NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NWBHDF5IO as a context manager\n",
    "`NWBHDF5IO` can also be used as a context manager.\n",
    "\n",
    "The advantage of using a context manager is that the file is closed automatically when the context finishes\n",
    "successfully or if there is an error. Be aware that if you use this method, closing the context (unindenting the code) will automatically close the `NWBHDF5IO` object and the corresponding h5py File object. The data not already read from the NWB file will then be inaccessible, so any code that reads data must be placed within the context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with NWBHDF5IO(filepath, mode=\"r\") as io2:\n",
    "    nwbfile2 = io2.read()\n",
    "\n",
    "    # data accessible here\n",
    "\n",
    "# data not accessible here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the NWB file contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing subject data\n",
    "\n",
    "Access `nwbfile.subject` to get information about the subject used in this experiment, including their age, sex, species, and ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing stimulus data\n",
    "\n",
    "Data representing stimuli that were presented to the experimental subject are stored in\n",
    "`stimulus` within the `NWBFile` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nwbfile.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``NWBFile.stimulus`` is a dictionary that can contain PyNWB objects representing\n",
    "different types of data, such as images (grayscale, RGB) or time series of images.\n",
    "In this file, ``NWBFile.stimulus`` contains a single key \"StimulusPresentation\" with an\n",
    "`OpticalSeries` object representing what images were shown to the subject and at what times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stimulus_presentation = nwbfile.stimulus[\"StimulusPresentation\"]\n",
    "stimulus_presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy loading of datasets\n",
    "Data arrays are read passively from the NWB file.\n",
    "Accessing the `data` attribute of the `OpticalSeries` object does not read the data values, but presents an `h5py.Dataset` object that can be indexed to read data.\n",
    "You can use the ``[:]`` operator to read the entire data array into memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentation.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_stimulus_data = stimulus_presentation.data[:]\n",
    "all_stimulus_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images may be 3D or 4D (grayscale or RGB), where the first dimension must be time (frame).\n",
    "The second and third dimensions represent x and y.\n",
    "The fourth dimension represents the RGB value (length of 3) for color images.\n",
    "\n",
    "This `OpticalSeries` data contains 200 images of size 400x300 pixels with three channels\n",
    "(red, green, and blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stimulus_presentation.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing datasets\n",
    "Especially with very large datasets, it is often preferable to read only a portion of the data. To do this, index or slice into the ``data`` attribute just like if you were indexing or slicing a numpy array.\n",
    "\n",
    "For example, let's look at a single image of the stimulus presentation data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_index = 31\n",
    "image = stimulus_presentation.data[frame_index]\n",
    "image = image[..., ::-1] # Reverse the last dimension because the data were stored in BGR instead of RGB\n",
    "plt.imshow(image, aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing NWB Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing single unit data\n",
    "Data and metadata about sorted single units are stored in a `Units`\n",
    "object. It stores metadata about each single unit in a tabular form, where each row represents\n",
    "a unit with spike times and additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nwbfile.units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the single unit data as a pandas `DataFrame`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "units_df = nwbfile.units.to_dataframe()\n",
    "units_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the spike times of the first single unit, index this pandas dataframe with the column name, “spike_times”, and the row index, 0. All times in NWB are stored in seconds relative to the session start time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "units_df[\"spike_times\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing spiking activity relative to stimulus onset\n",
    "We can look at when these single units spike relative to when image stimuli were presented to the subject.\n",
    "We will iterate over the first 3 units and get their spike times.\n",
    "Then for each unit, we will iterate over each stimulus onset time and compute the spike times relative\n",
    "to stimulus onset. Finally, we will create a raster plot and histogram of these aligned spike times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "before = 1.0  # in seconds\n",
    "after = 3.0\n",
    "\n",
    "# Get the stimulus times for all stimuli\n",
    "# get_timestamps() works whether the time is stored as an array of timestamps or as\n",
    "# starting time and sampling rate.\n",
    "stim_on_times = stimulus_presentation.get_timestamps()\n",
    "\n",
    "for unit in range(3):\n",
    "    unit_spike_times = nwbfile.units[\"spike_times\"][unit]\n",
    "    trial_spikes = []\n",
    "    for time in stim_on_times:\n",
    "        # Compute spike times relative to stimulus onset\n",
    "        aligned_spikes = unit_spike_times - time\n",
    "        # Keep only spike times in a given time window around the stimulus onset\n",
    "        aligned_spikes = aligned_spikes[\n",
    "            (-before < aligned_spikes) & (aligned_spikes < after)\n",
    "        ]\n",
    "        trial_spikes.append(aligned_spikes)\n",
    "    fig, axs = plt.subplots(2, 1, sharex=\"all\")\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    axs[0].eventplot(trial_spikes)\n",
    "\n",
    "    axs[0].set_ylabel(\"trial\")\n",
    "    axs[0].set_title(\"unit {}\".format(unit))\n",
    "    axs[0].axvline(0, color=[0.5, 0.5, 0.5], linestyle='dashed')\n",
    "\n",
    "    axs[1].hist(np.hstack(trial_spikes), 30)\n",
    "    axs[1].axvline(0, color=[0.5, 0.5, 0.5], linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing trials\n",
    "Trials are stored as `TimeIntervals` object which is a subclass of `DynamicTable`. `DynamicTable` objects are used to store metadata about each trial in a tabular form, where each row represents a trial and has a start time, stop time, and additional metadata.\n",
    "\n",
    "You can find more information about trials and time intervals in the [pynwb time intervals Tutorial](https://pynwb.readthedocs.io/en/latest/tutorials/general/plot_timeintervals.html#time-intervals)\n",
    "\n",
    "Similarly to `Units`, we can view trials as a pandas `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trials_df = nwbfile.trials.to_dataframe()\n",
    "trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing stimulus images by trial\n",
    "The stimulus can be mapped one-to-one to each row (trial) of `trials` based on the ``stim_on_time`` column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(stimulus_presentation.timestamps[:] == trials_df.stim_on_time[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will visualize the first 3 images that were categorized as landscapes in the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "stim_on_times_landscapes = trials_df[\n",
    "    trials_df.category_name == \"landscapes\"\n",
    "].stim_on_time\n",
    "for time in stim_on_times_landscapes.iloc[:3]:\n",
    "    img = np.squeeze(\n",
    "        stimulus_presentation.data[\n",
    "            np.where(stimulus_presentation.timestamps[:] == time)\n",
    "        ]\n",
    "    )\n",
    "    # Reverse the last dimension because the data were stored in BGR instead of RGB\n",
    "    img = img[..., ::-1]\n",
    "    plt.figure()\n",
    "    plt.imshow(img, aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration and visualization tools\n",
    "So far we have explored the NWB file by inspecting at the `NWBFile` object and accessing its attributes, but it may be useful to explore the data in a\n",
    "more interactive, visual way. See [Exploring NWB Files](https://nwb-overview.readthedocs.io/en/latest/tools/analysis_tools_home.html#analysistools-explore) in the analysis tool catalog for an updated list of programs for exploring NWB files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming data\n",
    "\n",
    "In some circumstances, you may want to work with very large NWB files or with subsets of data from an NWB file. Instead of downloading the full NWB file, another approach is to stream data directly from an archive. Streaming data allows you to read specific sections within individual data files directly from remote stores such as\n",
    "[DANDI](https://dandiarchive.org/).\n",
    "\n",
    "There are multiple methods to stream NWB files, we will focus on using `remfile` today but you can find additional options in the [pynwb streaming tutorial](https://pynwb.readthedocs.io/en/stable/tutorials/advanced_io/streaming.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the location of the file on DANDI\n",
    "First, you will use the `DandiAPIClient` get the S3 URL of the NWB file stored on DANDI. Similarly to downloading the file, we can use the dandiset ID and the path of the file within that dataset to get this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandiset_id = '000004'\n",
    "filepath = 'sub-P11HMH/sub-P11HMH_ses-20061101_ecephys+image.nwb'\n",
    "with DandiAPIClient() as client:\n",
    "    asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(filepath)\n",
    "    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using remfile to stream data\n",
    "`remfile` is a library that enables indexing and streaming of files in s3. `remfile` is simple and fast, especially for the initial load of the nwb file and for accessing small pieces of data. The caveats of `remfile` are that it is a new project that has not been tested in a variety of use-cases and caching options are limited compared to other methods such as `fsspec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_file = remfile.File(s3_url)\n",
    "\n",
    "file = h5py.File(rem_file, \"r\")\n",
    "io_stream = NWBHDF5IO(file=file)\n",
    "nwbfile_stream = io_stream.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how we can still get a simplified interactive representation of the nwb file contents after streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with the data in the same way as downloading the full file, but now we will stream the data on demand as we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame_index = 31\n",
    "image = nwbfile_stream.stimulus['StimulusPresentation'].data[frame_index]\n",
    "image = image[..., ::-1] # Reverse the last dimension because the data were stored in BGR instead of RGB\n",
    "plt.imshow(image, aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the open NWB files\n",
    "It is good practice to close any files that you have opened.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "io.close()         # downloaded io object\n",
    "io_stream.close()  # streaming io object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
